(this["webpackJsonpreact-deploy"]=this["webpackJsonpreact-deploy"]||[]).push([[0],[,,function(e,t,a){},,function(e,t,a){e.exports=a.p+"static/media/tony.7fbc3449.jpg"},function(e,t,a){e.exports=a.p+"static/media/ryan.ec78bca4.jfif"},function(e,t,a){e.exports=a.p+"static/media/allan.7b18ebb2.jfif"},function(e,t,a){e.exports=a.p+"static/media/gen3-robot.fe199288.webp"},function(e,t,a){e.exports=a.p+"static/media/food.88e4ec52.png"},function(e,t,a){e.exports=a.p+"static/media/technical-overview.6d4fecfa.png"},function(e,t,a){e.exports=a.p+"static/media/system-setup.3edd80f8.png"},function(e,t,a){e.exports=a(17)},,,,,function(e,t,a){},function(e,t,a){"use strict";a.r(t);var n=a(0),i=a.n(n),r=a(3),o=a.n(r),s=(a(16),a(4)),l=a.n(s),c=a(5),m=a.n(c),h=a(6),p=a.n(h),d=a(7),g=a.n(d),u=a(8),f=a.n(u),y=a(9),E=a.n(y),w=a(10),b=a.n(w);a(2);var x=function(){return i.a.createElement("div",null,i.a.createElement("p",{className:"Paragraph",style:{lineHeight:1.5,fontSize:"26px",fontWeight:"bold"}},"Build Blog"),i.a.createElement("p",{className:"Paragraph",style:{lineHeight:1.5}},"Week 0"),i.a.createElement("p",{className:"Paragraph",style:{lineHeight:1.5}},"[Jan 19th] The team had a meeting with Prof. Behrad Khamesee and Prof. Andrew Kennings.\xa0 The team presented the project plan to the professors,\xa0 updated the professors on the progress,\xa0 and asked questions regarding the deliverables and expectations in MTE482."),i.a.createElement("p",{className:"Paragraph",style:{lineHeight:1.5}},"[Jan 20th] Tony worked on setting up the build blog section on top of the existing project website."))};var v=function(){return i.a.createElement("div",{className:"App"},i.a.createElement("div",{className:"App-container"},i.a.createElement("div",{className:"Fixed-header"},i.a.createElement("p",{className:"Title"},"TRON Robotic Feeder"),i.a.createElement("p",{className:"Subtitle"},"Ready to help you eat at any moment.")),i.a.createElement("div",{style:{height:"600px",width:"100%",marginTop:"200px",display:"flex",alignItems:"end",justifyContent:"space-around"}},i.a.createElement("div",{style:{width:"700px",display:"flex",alignItems:"end",justifyContent:"space-around"}},i.a.createElement("img",{style:{height:"100px"},src:f.a}),i.a.createElement("img",{style:{height:"500px"},src:g.a})),i.a.createElement("div",{style:{width:"400px",background:"white",padding:"50px",marginBottom:"30px"}},i.a.createElement("p",{className:"Heading"},"Introducing"),i.a.createElement("p",{className:"Heading"},"the TRON Robotic Feeder"),i.a.createElement("br",null),i.a.createElement("p",{className:"Paragraph",style:{lineHeight:1.5}}," The robotic feeder is a system designed to help people with disabilities to have meals more easily without moving their arms or upper body. "),i.a.createElement("p",{className:"Paragraph",style:{lineHeight:1.5}}," This system primarily comprises a robotic arm with a built-in gripper and an RGBD camera. Knowing what food the user wants through linguistic inputs, the system will then search for the target food on the table using computer vision, use a fork to skewer it, locate and then deliver the food to the user\u2019s mouth. "))),i.a.createElement("div",{style:{width:"800px",background:"white",padding:"50px",margin:"30px"}},i.a.createElement(x,null)),i.a.createElement("div",{style:{height:"650px",width:"100%",background:"white"}},i.a.createElement("p",{className:"Title"},"\u2014 Meet Our Team \u2014"),i.a.createElement("div",{style:{height:"300px",width:"100%",display:"flex",alignItems:"center",justifyContent:"space-around"}},i.a.createElement("div",{style:{height:"100%",width:"30%",display:"flex",alignItems:"center",justifyContent:"center"}},i.a.createElement("img",{src:l.a,className:"App-profile",alt:"Profile"})),i.a.createElement("div",{style:{height:"100%",width:"30%",display:"flex",alignItems:"center",justifyContent:"center"}},i.a.createElement("img",{src:m.a,className:"App-profile",alt:"Profile"})),i.a.createElement("div",{style:{height:"100%",width:"30%",display:"flex",alignItems:"center",justifyContent:"center"}},i.a.createElement("img",{src:p.a,className:"App-profile",alt:"Profile"}))),i.a.createElement("div",{style:{height:"200px",width:"100%",display:"flex",alignItems:"center",justifyContent:"space-around"}},i.a.createElement("div",{style:{width:"350px"}},i.a.createElement("p",{className:"Heading"},"Tony Cui"),i.a.createElement("p",{className:"Paragraph"}," Tony in his past internships has been primarily exploring web development (SaaS) and robotic control. "),i.a.createElement("p",{className:"Paragraph"}," In this project, Tony will be working on the UI and robotic control. ")),i.a.createElement("div",{style:{width:"350px"}},i.a.createElement("p",{className:"Heading"},"Ryan Zhou"),i.a.createElement("p",{className:"Paragraph"}," Ryan is a team player that has expertise in camera-based robotics development and basic CV operations. "),i.a.createElement("p",{className:"Paragraph"}," In this project, Ryan will be working on the perception module that uses computer vision. ")),i.a.createElement("div",{style:{width:"350px"}},i.a.createElement("p",{className:"Heading"},"Allan Zhao"),i.a.createElement("p",{className:"Paragraph"}," Allan has extensive exposure to robotics manipulation, task and motion planning, and computer vision. "),i.a.createElement("p",{className:"Paragraph"}," In this project, Allan will be working on the robot manipulation module. ")))),i.a.createElement("div",{style:{height:"800px",width:"100%",marginTop:"50px",display:"flex",alignItems:"center",justifyContent:"space-around",background:"white"}},i.a.createElement("div",{style:{width:"400px",background:"white",padding:"50px",marginBottom:"30px"}},i.a.createElement("p",{className:"Heading"},"System Setup"),i.a.createElement("br",null),i.a.createElement("p",{className:"Paragraph",style:{lineHeight:1.5}}," The robotic feeder will be fixed on one side of the table and the user will be sitting on the other side. In order for the robot to successfully deliver food to the user\u2019s mouth, the robotic arm is required to be mounted 0.6m to 0.8m away from where the user sits. The food can be placed anywhere between the user and the robot. "),i.a.createElement("p",{className:"Paragraph",style:{lineHeight:1.5}}," During each cycle of the operations, the robot will: "),i.a.createElement("p",{className:"Paragraph",style:{lineHeight:1.5}}," 1) Identify through the camera the food that the user signals it to fetch, "),i.a.createElement("p",{className:"Paragraph",style:{lineHeight:1.5}}," 2) Use the end effector (mounted at the tip of the robot arm) that holds a fork to skewer the target food item, "),i.a.createElement("p",{className:"Paragraph",style:{lineHeight:1.5}}," 3) Locate the user\u2019s mouth again through the camera, and "),i.a.createElement("p",{className:"Paragraph",style:{lineHeight:1.5}}," 4) Deliver the food to the user\u2019s mouth. ")),i.a.createElement("div",{style:{width:"800px",display:"flex",flexDirection:"column",alignItems:"center",justifyContent:"space-around",background:"white"}},i.a.createElement("img",{style:{width:"60%",margin:"auto"},src:b.a}))),i.a.createElement("div",{style:{height:"800px",width:"100%",marginTop:"50px",display:"flex",alignItems:"center",justifyContent:"space-around",background:"white"}},i.a.createElement("div",{style:{width:"800px",display:"flex",flexDirection:"column",alignItems:"center",justifyContent:"space-around",background:"white"}},i.a.createElement("img",{style:{width:"80%"},src:E.a})),i.a.createElement("div",{style:{width:"400px",background:"white",padding:"50px",marginBottom:"30px"}},i.a.createElement("p",{className:"Heading"},"Technical Implementation"),i.a.createElement("br",null),i.a.createElement("p",{className:"Paragraph",style:{lineHeight:1.5}}," The overall robot feeder system contains two main modules: the perception module and manipulation module. "),i.a.createElement("p",{className:"Paragraph",style:{lineHeight:1.5}}," Initially, a user sends a natural language command to the system either by speaking or typing the name of desired food into the system."),i.a.createElement("p",{className:"Paragraph",style:{lineHeight:1.5}}," Next, the perception module scans the scene using a camera with depth information, detects every food item on the table,and stores this information for further use by the robot."),i.a.createElement("p",{className:"Paragraph",style:{lineHeight:1.5}}," Given the instruction from the user and exact location of food items, the manipulation module generates the robot actions and commands that control the robot to pick and feed food into the user\u2019s mouth."))),i.a.createElement("div",{className:"PortfolioContainer"})))};Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));o.a.render(i.a.createElement(i.a.StrictMode,null,i.a.createElement(v,null)),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then((function(e){e.unregister()})).catch((function(e){console.error(e.message)}))}],[[11,1,2]]]);
//# sourceMappingURL=main.58cbc48a.chunk.js.map